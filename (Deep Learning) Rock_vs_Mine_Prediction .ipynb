{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYSLvRgB3Sel"
   },
   "source": [
    "## Sonar Waves (Mine or Rock)\n",
    "\n",
    "Sonar technology can be used to detect and classify underwater objects such as rocks and mines. The process typically involves emitting sound waves and analyzing the returning echoes to determine the characteristics of the objects in the water. This information can then be used to identify and locate rocks and mines.\n",
    "\n",
    "There are different types of sonar systems that can be used for this purpose, including active sonar, which emits a sound signal and listens for the return, and passive sonar, which listens for the sound emitted by a target.\n",
    "\n",
    "![Medical](https://www.ausseabed.gov.au/__data/assets/image/0013/61222/multibeam.png)\n",
    "\n",
    "In order to classify objects as rocks or mines, the sonar data is usually processed and analyzed using algorithms, such as machine learning algorithms, that can identify specific features of the objects based on the characteristics of the echoes.\n",
    "\n",
    "It's important to note that sonar detection is not 100% accurate and can be affected by environmental conditions such as water temperature, salinity, and sound absorption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCLGacZR4UZx"
   },
   "source": [
    "## Data Collection and Data Processing\n",
    "\n",
    "Data processing, on the other hand, is the process of converting raw data into a format that can be analyzed and understood. This may involve cleaning and organizing the data, transforming it into a specific format, and running statistical or machine learning algorithms on it to extract insights and information.\n",
    "\n",
    "Data collection and data processing are closely related, as the quality and accuracy of the processed data depend on the methods and instruments used for data collection.\n",
    "\n",
    "In the context of sonar data, data collection would involve the use of sonar equipment to collect data on underwater objects, while data processing would involve cleaning and analyzing the collected data to identify and classify objects as rocks or mines.\n",
    "\n",
    "Data Processing steps can be divided into several stages:\n",
    "\n",
    "- Data cleaning: to remove or correct errors and inconsistencies in the data.\n",
    "- Data integration: combine data from multiple sources.\n",
    "- Data transformation: convert the data into a format that can be analyzed.\n",
    "- Data reduction: Reduce the data set to a smaller set of relevant data.\n",
    "- Data mining: Extracting information and knowledge from the data using statistical, machine learning or other techniques.\n",
    "- Data visualization: Visualize the results of the analysis in order to make it more understandable.\n",
    "\n",
    "After the data is processed, it can be used for a variety of purposes such as making predictions, identifying patterns, and detecting anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "This dataset was used in Gorman, R. P., and Sejnowski, T. J. (1988). “Analysis of Hidden Units in a Layered Network Trained to Classify Sonar Targets” in Neural Networks, Vol. 1, pp. 75-89.\n",
    "\n",
    "The CSV files contain data regarding sonar signals bounced off a metal cylinder (mines - M) and a roughly cylindrical rock (rock - R) at various angles and under various conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ymxgj2i3RwO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://cainvas-static.s3.amazonaws.com/media/user_data/cainvas-admin/sonar.all-data.csv', header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN_FI_eN48V_",
    "outputId": "5d4d105c-657c-4eec-df90-e2f4a0cbf837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The spread of labels in the dataframe\n",
    "\n",
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Categorical features Handling\n",
    "The class attribute has R and M to denote the classes. We have to convert them into numeric values.\n",
    "\n",
    "Categorical features are features in a dataset that can be divided into categories. These features often have a limited number of distinct values and can be either ordinal (values have a natural ordering) or nominal (values do not have a natural ordering). Handling categorical features in a machine learning model typically involves encoding them into numerical values, such as using one-hot encoding or ordinal encoding. It is important to ensure that the encoding is done correctly to avoid introducing bias or affecting the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "q6A1r9J-5aOJ",
    "outputId": "9efbb9de-570b-4d9f-a92a-d6835f3acb2d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   0  \n",
       "1    0.0052  0.0044   0  \n",
       "2    0.0095  0.0078   0  \n",
       "3    0.0040  0.0117   0  \n",
       "4    0.0107  0.0094   0  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   1  \n",
       "204  0.0062  0.0067   1  \n",
       "205  0.0077  0.0031   1  \n",
       "206  0.0036  0.0048   1  \n",
       "207  0.0061  0.0115   1  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60] = (df[60] == 'M').astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the class names corresponding to the index in arrays for reference later.\n",
    "\n",
    "class_names = ['Rocks', 'Mines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing Dataset\n",
    "\n",
    "Even though there is only a difference of only 14 samples, in comparison to the total number of data samples available, this needs to be balanced.\n",
    "\n",
    "Data balancing refers to the process of adjusting the distribution of samples in a dataset to address class imbalance. Class imbalance occurs when the number of samples in one class is much larger or smaller than the number of samples in other classes. This can be a problem in machine learning because it can lead to a model that is biased towards the majority class, resulting in poor performance on the minority class.\n",
    "\n",
    "There are several techniques to balance data, such as:\n",
    "\n",
    "- oversampling the minority class by duplicating samples\n",
    "- undersampling the majority class by removing samples\n",
    "\n",
    "synthetic data generation by creating new samples using techniques such as SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "It's important to note that oversampling techniques can lead to overfitting, while undersampling techniques can lead to loss of information. Therefore, it's important to evaluate the model performance on both training and validation set to check for overfitting. Additionally, it's important to consider the cost of misclassification for the specific problem to decide which class to balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating into 2 dataframes, one for each class \n",
    "\n",
    "df0 = df[df[60] == 0]\n",
    "df1 = df[df[60] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in:\n",
      "Class label 0 -  97\n",
      "Class label 1 -  111\n",
      "\n",
      "After resampling - \n",
      "Number of samples in:\n",
      "Class label 0 -  111\n",
      "Class label 1 -  111\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in:\")\n",
    "print(\"Class label 0 - \", len(df0))\n",
    "print(\"Class label 1 - \", len(df1))\n",
    "\n",
    "# Upsampling \n",
    "\n",
    "df0 = df0.sample(len(df1), replace = True)    # replace = True enables resampling\n",
    "\n",
    "print('\\nAfter resampling - ')\n",
    "\n",
    "print(\"Number of samples in:\")\n",
    "print(\"Class label 0 - \", len(df0))\n",
    "print(\"Class label 1 - \", len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 222\n"
     ]
    }
   ],
   "source": [
    "# concatente to form a single dataframe\n",
    "\n",
    "df = pd.concat([df1, df0])\n",
    "\n",
    "print('Total number of samples:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qRShuFc46jLd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input columns:  60\n",
      "Number of output columns:  1\n"
     ]
    }
   ],
   "source": [
    "# defining the input and output columns to separate the dataset in the later cells.\n",
    "\n",
    "input_columns = list(df.columns[:-1]) \n",
    "output_columns = [df.columns[-1]]\n",
    "\n",
    "print(\"Number of input columns: \", len(input_columns))\n",
    "#print(\"Input columns: \", ', '.join(input_columns))\n",
    "\n",
    "print(\"Number of output columns: \", len(output_columns))\n",
    "#print(\"Output columns: \", ', '.join(output_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j912DrKe7L03"
   },
   "source": [
    "## Data Splitting \n",
    "\n",
    "After separating the data and labels, it is common practice to further divide the data into two sets: a training set and a test set.\n",
    "\n",
    "The training set is used to train the machine learning model and consists of a portion of the data and its corresponding labels. The model learns to make predictions based on the relationships and patterns in the training data.\n",
    "\n",
    "The test set, on the other hand, is used to evaluate the performance of the trained model. It consists of a different portion of the data and its corresponding labels that the model has not seen during the training process. This set is used to assess the model's ability to generalize and make accurate predictions on unseen data.\n",
    "\n",
    "Data splitting is an important step in the machine learning process because it ensures that the model is being evaluated on data it has not seen before, which gives a better understanding of the model's real-world performance.\n",
    "\n",
    "The common practice is to split the data into a 70-80% training set and a 20-30% test set, but the ratio of the split can vary based on the size of the dataset and the specific application.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bTnEFld87GIr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in...\n",
      "Training set:  199\n",
      "Validation set:  23\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and val set -- 90-10 split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size = 0.1, random_state = 2)\n",
    "\n",
    "print(\"Number of samples in...\")\n",
    "print(\"Training set: \", len(train_df))\n",
    "print(\"Validation set: \", len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - \n",
      "1    100\n",
      "0     99\n",
      "Name: 60, dtype: int64\n",
      "\n",
      "Validation - \n",
      "0    12\n",
      "1    11\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looking into the spread of values in the train and val sets\n",
    "\n",
    "print(\"Training - \")\n",
    "print(train_df[60].value_counts())\n",
    "\n",
    "print(\"\\nValidation - \")\n",
    "print(val_df[60].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into X (input) and y (output)\n",
    "\n",
    "Xtrain, ytrain = np.array(train_df[input_columns]), np.array(train_df[output_columns])\n",
    "\n",
    "Xval, yval = np.array(val_df[input_columns]), np.array(val_df[output_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>222.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.028330</td>\n",
       "      <td>0.037425</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.052344</td>\n",
       "      <td>0.072121</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.122163</td>\n",
       "      <td>0.131581</td>\n",
       "      <td>0.170653</td>\n",
       "      <td>0.202018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.009209</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022779</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.038743</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>0.059479</td>\n",
       "      <td>0.083679</td>\n",
       "      <td>0.114641</td>\n",
       "      <td>0.128975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009387</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.50113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.014675</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.080275</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020950</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.086150</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.096250</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.156850</td>\n",
       "      <td>0.168400</td>\n",
       "      <td>0.227525</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.014875</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  222.000000  222.000000  222.000000  222.000000  222.000000  222.000000   \n",
       "mean     0.028330    0.037425    0.043147    0.052344    0.072121    0.100405   \n",
       "std      0.022779    0.034333    0.038743    0.046158    0.054396    0.054819   \n",
       "min      0.001500    0.000600    0.001500    0.006100    0.007600    0.011600   \n",
       "25%      0.013200    0.014675    0.018800    0.023200    0.037350    0.064400   \n",
       "50%      0.020950    0.030850    0.033750    0.038700    0.059700    0.086150   \n",
       "75%      0.036050    0.045400    0.057300    0.062700    0.096250    0.130600   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.307000   \n",
       "\n",
       "               6           7           8           9   ...          51  \\\n",
       "count  222.000000  222.000000  222.000000  222.000000  ...  222.000000   \n",
       "mean     0.122163    0.131581    0.170653    0.202018  ...    0.012823   \n",
       "std      0.059479    0.083679    0.114641    0.128975  ...    0.009387   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000800   \n",
       "25%      0.081700    0.080275    0.089900    0.109300  ...    0.006600   \n",
       "50%      0.105600    0.111700    0.145500    0.180800  ...    0.009850   \n",
       "75%      0.156850    0.168400    0.227525    0.266600  ...    0.016300   \n",
       "max      0.332200    0.459000    0.682800    0.710600  ...    0.070900   \n",
       "\n",
       "               52          53          54          55          56          57  \\\n",
       "count  222.000000  222.000000  222.000000  222.000000  222.000000  222.000000   \n",
       "mean     0.010096    0.010904    0.009209    0.007708    0.007957    0.007755   \n",
       "std      0.007030    0.007387    0.007149    0.005443    0.005750    0.006265   \n",
       "min      0.000500    0.001000    0.000600    0.000400    0.000900    0.000600   \n",
       "25%      0.004250    0.004825    0.003800    0.004500    0.003700    0.003500   \n",
       "50%      0.008050    0.009600    0.007500    0.006150    0.006100    0.005900   \n",
       "75%      0.014175    0.014875    0.012100    0.009775    0.010875    0.010200   \n",
       "max      0.039000    0.035200    0.044700    0.039400    0.035500    0.044000   \n",
       "\n",
       "               58          59         60  \n",
       "count  222.000000  222.000000  222.00000  \n",
       "mean     0.007491    0.006415    0.50000  \n",
       "std      0.005909    0.004892    0.50113  \n",
       "min      0.000100    0.000600    0.00000  \n",
       "25%      0.003300    0.003000    0.00000  \n",
       "50%      0.005900    0.005450    0.50000  \n",
       "75%      0.009450    0.008000    1.00000  \n",
       "max      0.036400    0.043900    1.00000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\n",
    "\n",
    "Data scaling refers to the process of normalizing or standardizing the values of the features in a dataset to ensure that all features are on a similar scale. This is important in machine learning because many models, such as neural networks and distance-based algorithms, are sensitive to the scale of the input features. Scaling the data can help the model converge faster and improve its performance.\n",
    "\n",
    "There are several techniques to scale data:\n",
    "\n",
    "- Min-Max Scaling: This scales the data to a specific range, such as [0,1]. It is calculated by (x-min)/(max-min)\n",
    "- Standardization: This scales the data to have a mean of 0 and a standard deviation of 1. It is calculated by (x-mean)/stddev\n",
    "- Z-score normalization: This scales the data to have a mean of 0 and a standard deviation of 1. It is calculated by (x-mean)/stddev\n",
    "\n",
    "It's important to note that, for certain types of models, such as decision trees, scaling the data is not necessary as they are not affected by the scale of the input features. Additionally, for some data like time series, scaling the data can lead to losing the temporal relationship of the data, it's important to consider the specific problem and the model type before scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard scaler to standardize them to values with mean = 0 and variance = 1.\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set alone\n",
    "Xtrain = standard_scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Use it to transform val and test input\n",
    "Xval = standard_scaler.transform(Xval)\n",
    "#Xtest = standard_scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.076899e-17</td>\n",
       "      <td>6.694812e-17</td>\n",
       "      <td>-1.829915e-16</td>\n",
       "      <td>-2.231604e-18</td>\n",
       "      <td>-3.046140e-16</td>\n",
       "      <td>3.074035e-16</td>\n",
       "      <td>2.811821e-16</td>\n",
       "      <td>-2.343184e-16</td>\n",
       "      <td>3.168878e-16</td>\n",
       "      <td>1.193908e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.531664e-17</td>\n",
       "      <td>-1.368252e-16</td>\n",
       "      <td>-9.205367e-18</td>\n",
       "      <td>2.108866e-16</td>\n",
       "      <td>-6.248491e-17</td>\n",
       "      <td>1.295725e-16</td>\n",
       "      <td>3.886129e-17</td>\n",
       "      <td>-3.180036e-17</td>\n",
       "      <td>1.623492e-16</td>\n",
       "      <td>-1.724960e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "      <td>1.002522e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.181228e+00</td>\n",
       "      <td>-1.078751e+00</td>\n",
       "      <td>-1.095681e+00</td>\n",
       "      <td>-9.693369e-01</td>\n",
       "      <td>-1.148231e+00</td>\n",
       "      <td>-1.626850e+00</td>\n",
       "      <td>-2.055002e+00</td>\n",
       "      <td>-1.554987e+00</td>\n",
       "      <td>-1.458269e+00</td>\n",
       "      <td>-1.410223e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.168520e+00</td>\n",
       "      <td>-1.287978e+00</td>\n",
       "      <td>-1.332847e+00</td>\n",
       "      <td>-1.313575e+00</td>\n",
       "      <td>-1.223510e+00</td>\n",
       "      <td>-1.311264e+00</td>\n",
       "      <td>-1.201918e+00</td>\n",
       "      <td>-1.150819e+00</td>\n",
       "      <td>-1.244529e+00</td>\n",
       "      <td>-1.188813e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.706738e-01</td>\n",
       "      <td>-6.433093e-01</td>\n",
       "      <td>-6.494969e-01</td>\n",
       "      <td>-6.166531e-01</td>\n",
       "      <td>-6.516010e-01</td>\n",
       "      <td>-6.405968e-01</td>\n",
       "      <td>-6.490028e-01</td>\n",
       "      <td>-6.355766e-01</td>\n",
       "      <td>-6.945734e-01</td>\n",
       "      <td>-7.621342e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.168984e-01</td>\n",
       "      <td>-6.560454e-01</td>\n",
       "      <td>-8.137379e-01</td>\n",
       "      <td>-8.306571e-01</td>\n",
       "      <td>-7.670502e-01</td>\n",
       "      <td>-5.998542e-01</td>\n",
       "      <td>-7.266778e-01</td>\n",
       "      <td>-6.671849e-01</td>\n",
       "      <td>-6.858944e-01</td>\n",
       "      <td>-6.893331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.259407e-01</td>\n",
       "      <td>-1.819993e-01</td>\n",
       "      <td>-2.443409e-01</td>\n",
       "      <td>-3.018696e-01</td>\n",
       "      <td>-2.192830e-01</td>\n",
       "      <td>-2.753866e-01</td>\n",
       "      <td>-2.413667e-01</td>\n",
       "      <td>-2.549834e-01</td>\n",
       "      <td>-2.372339e-01</td>\n",
       "      <td>-1.736922e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.648175e-01</td>\n",
       "      <td>-3.454344e-01</td>\n",
       "      <td>-3.367191e-01</td>\n",
       "      <td>-1.844993e-01</td>\n",
       "      <td>-2.107399e-01</td>\n",
       "      <td>-2.715110e-01</td>\n",
       "      <td>-3.193288e-01</td>\n",
       "      <td>-2.819172e-01</td>\n",
       "      <td>-2.796149e-01</td>\n",
       "      <td>-2.098319e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.460707e-01</td>\n",
       "      <td>2.088926e-01</td>\n",
       "      <td>3.403145e-01</td>\n",
       "      <td>2.287353e-01</td>\n",
       "      <td>4.291940e-01</td>\n",
       "      <td>5.421653e-01</td>\n",
       "      <td>5.462692e-01</td>\n",
       "      <td>4.438909e-01</td>\n",
       "      <td>5.080276e-01</td>\n",
       "      <td>4.900734e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.158369e-01</td>\n",
       "      <td>3.721843e-01</td>\n",
       "      <td>5.331386e-01</td>\n",
       "      <td>5.636834e-01</td>\n",
       "      <td>4.168922e-01</td>\n",
       "      <td>2.939689e-01</td>\n",
       "      <td>4.868826e-01</td>\n",
       "      <td>4.066462e-01</td>\n",
       "      <td>3.128760e-01</td>\n",
       "      <td>3.895445e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.735963e+00</td>\n",
       "      <td>5.626770e+00</td>\n",
       "      <td>6.709982e+00</td>\n",
       "      <td>7.880395e+00</td>\n",
       "      <td>5.879616e+00</td>\n",
       "      <td>3.812373e+00</td>\n",
       "      <td>3.625995e+00</td>\n",
       "      <td>3.985913e+00</td>\n",
       "      <td>4.469588e+00</td>\n",
       "      <td>3.876196e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.035297e+00</td>\n",
       "      <td>6.220241e+00</td>\n",
       "      <td>4.068689e+00</td>\n",
       "      <td>3.297951e+00</td>\n",
       "      <td>5.067076e+00</td>\n",
       "      <td>5.802838e+00</td>\n",
       "      <td>4.670696e+00</td>\n",
       "      <td>5.964337e+00</td>\n",
       "      <td>4.900449e+00</td>\n",
       "      <td>7.462186e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02   \n",
       "mean   5.076899e-17  6.694812e-17 -1.829915e-16 -2.231604e-18 -3.046140e-16   \n",
       "std    1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00   \n",
       "min   -1.181228e+00 -1.078751e+00 -1.095681e+00 -9.693369e-01 -1.148231e+00   \n",
       "25%   -6.706738e-01 -6.433093e-01 -6.494969e-01 -6.166531e-01 -6.516010e-01   \n",
       "50%   -3.259407e-01 -1.819993e-01 -2.443409e-01 -3.018696e-01 -2.192830e-01   \n",
       "75%    3.460707e-01  2.088926e-01  3.403145e-01  2.287353e-01  4.291940e-01   \n",
       "max    4.735963e+00  5.626770e+00  6.709982e+00  7.880395e+00  5.879616e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02   \n",
       "mean   3.074035e-16  2.811821e-16 -2.343184e-16  3.168878e-16  1.193908e-16   \n",
       "std    1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00   \n",
       "min   -1.626850e+00 -2.055002e+00 -1.554987e+00 -1.458269e+00 -1.410223e+00   \n",
       "25%   -6.405968e-01 -6.490028e-01 -6.355766e-01 -6.945734e-01 -7.621342e-01   \n",
       "50%   -2.753866e-01 -2.413667e-01 -2.549834e-01 -2.372339e-01 -1.736922e-01   \n",
       "75%    5.421653e-01  5.462692e-01  4.438909e-01  5.080276e-01  4.900734e-01   \n",
       "max    3.812373e+00  3.625995e+00  3.985913e+00  4.469588e+00  3.876196e+00   \n",
       "\n",
       "       ...            50            51            52            53  \\\n",
       "count  ...  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02   \n",
       "mean   ...  7.531664e-17 -1.368252e-16 -9.205367e-18  2.108866e-16   \n",
       "std    ...  1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00   \n",
       "min    ... -1.168520e+00 -1.287978e+00 -1.332847e+00 -1.313575e+00   \n",
       "25%    ... -6.168984e-01 -6.560454e-01 -8.137379e-01 -8.306571e-01   \n",
       "50%    ... -1.648175e-01 -3.454344e-01 -3.367191e-01 -1.844993e-01   \n",
       "75%    ...  4.158369e-01  3.721843e-01  5.331386e-01  5.636834e-01   \n",
       "max    ...  7.035297e+00  6.220241e+00  4.068689e+00  3.297951e+00   \n",
       "\n",
       "                 54            55            56            57            58  \\\n",
       "count  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02  1.990000e+02   \n",
       "mean  -6.248491e-17  1.295725e-16  3.886129e-17 -3.180036e-17  1.623492e-16   \n",
       "std    1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00  1.002522e+00   \n",
       "min   -1.223510e+00 -1.311264e+00 -1.201918e+00 -1.150819e+00 -1.244529e+00   \n",
       "25%   -7.670502e-01 -5.998542e-01 -7.266778e-01 -6.671849e-01 -6.858944e-01   \n",
       "50%   -2.107399e-01 -2.715110e-01 -3.193288e-01 -2.819172e-01 -2.796149e-01   \n",
       "75%    4.168922e-01  2.939689e-01  4.868826e-01  4.066462e-01  3.128760e-01   \n",
       "max    5.067076e+00  5.802838e+00  4.670696e+00  5.964337e+00  4.900449e+00   \n",
       "\n",
       "                 59  \n",
       "count  1.990000e+02  \n",
       "mean  -1.724960e-16  \n",
       "std    1.002522e+00  \n",
       "min   -1.188813e+00  \n",
       "25%   -6.893331e-01  \n",
       "50%   -2.098319e-01  \n",
       "75%    3.895445e-01  \n",
       "max    7.462186e+00  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Neural Network\n",
    "\n",
    "Modeling with neural networks is a popular approach in machine learning for a wide range of tasks, including image recognition, natural language processing, and time series forecasting. Neural networks are a type of model inspired by the structure and function of the human brain and are composed of layers of interconnected nodes or \"neurons.\"\n",
    "\n",
    "The process of building a neural network model typically involves the following steps:\n",
    "\n",
    "1. Define the architecture of the network, including the number of layers, the number of neurons in each layer, and the type of activation function to be used.\n",
    "2. Initialize the model's parameters, such as the weights and biases of the neurons.\n",
    "3. Feed the input data into the network and propagate it through the layers to obtain the output.\n",
    "4. Use a loss function to measure the difference between the predicted output and the true output.\n",
    "5. Use an optimizer to adjust the model's parameters to minimize the loss.\n",
    "6. Repeat steps 3-5 for multiple epochs using the training data.\n",
    "7. Evaluate the model's performance on the validation or test data.\n",
    "8. Repeat steps 3-7 with different architectures and hyperparameters to find the best model.\n",
    "\n",
    "It's important to note that neural networks can be prone to overfitting, which occurs when a model is too complex and memorizes the training data. To avoid overfitting, techniques such as regularization, early stopping, and dropout can be used. Additionally, it's important to have enough data to train the model and monitor the performance during the training to stop it when it's no longer improving.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                3904      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,529\n",
      "Trainable params: 6,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation = 'relu', input_shape = Xtrain[0].shape),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(16, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "cb = [EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 66ms/step - loss: 0.5557 - accuracy: 0.6935 - val_loss: 0.6761 - val_accuracy: 0.7391\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2491 - accuracy: 0.9196 - val_loss: 0.2135 - val_accuracy: 0.9130\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 0.9447 - val_loss: 0.1433 - val_accuracy: 0.8696\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9849 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 5.0329e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.7470e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.1241e-04 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.0840e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.7149e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history1 = model.fit(Xtrain, ytrain, validation_data = (Xval, yval), epochs=16, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tcg9Er11_TSv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0102 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010160206817090511, 1.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xval, yval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 23ms/step - loss: 4.1422e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4801e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 9.5196e-05 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.2606e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.1738e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4331e-05 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9515e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5782e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3535e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1739e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.0293e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 9.3697e-06 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 8.3740e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 7.5555e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 6.9249e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 6.3807e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(Xtrain, ytrain, validation_data = (Xval, yval), epochs=16, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history1, history2, variable1, variable2):\n",
    "    # combining metrics from both trainings    \n",
    "    var1_history = history1[variable1]\n",
    "    var1_history.extend(history2[variable1])\n",
    "    \n",
    "    var2_history = history1[variable2]\n",
    "    var2_history.extend(history2[variable2])\n",
    "    \n",
    "    # plotting them\n",
    "    plt.plot(range(len(var1_history)), var1_history)\n",
    "    plt.plot(range(len(var2_history)), var2_history)\n",
    "    plt.legend([variable1, variable2])\n",
    "    plt.title(variable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history1.history, history2.history, \"accuracy\", 'val_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history1.history, history2.history, \"loss\", 'val_loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to make Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:  Rocks\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "Predicted:  Rocks ( 1.65114e-09 --> 0 )\n"
     ]
    }
   ],
   "source": [
    "# pick random test data sample from one batch\n",
    "x = random.randint(0, len(Xval) - 1)\n",
    "\n",
    "output_true = np.array(yval)[x][0]\n",
    "print(\"True: \", class_names[output_true])\n",
    "\n",
    "output = model.predict(Xval[x].reshape(1, -1))[0][0]\n",
    "pred = int(output>0.5)    # finding max\n",
    "print(\"Predicted: \", class_names[pred], \"(\",output, \"-->\", pred, \")\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
